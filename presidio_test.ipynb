{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSTALL DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install presidio_analyzer\n",
    "%pip install presidio_anonymizer\n",
    "%pip install transformers\n",
    "%pip install pandas\n",
    "%pip install spacy\n",
    "%pip install torch\n",
    "%pip install seqeval\n",
    "%pip install spacy-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTALL SIMPLE SPACY MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSTALL COMPLEX SPACY MODEL (ONLY IF YOU USE THIS INSTEAD OF BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gonzalo.zelinka/Desktop/PII_POC/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import AnalyzerEngine, RecognizerResult, RecognizerRegistry\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_analyzer.nlp_engine import NlpEngineProvider\n",
    "import pandas as pd\n",
    "from transformers_rec import (\n",
    "    TransformersRecognizer,\n",
    "    BERT_DEID_CONFIGURATION,\n",
    ")\n",
    "import logging\n",
    "from presidio_anonymizer.entities import OperatorConfig\n",
    "from typing import List\n",
    "from spacy import displacy\n",
    "import csv\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "from seqeval.metrics import recall_score\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE ANALYZER AND ANONYMIZE FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzer_engine(model_path):\n",
    "  \"\"\"Return AnalyzerEngine.\n",
    "    :param model_path: Which model to use for NER:\n",
    "        \"obi/deid_roberta_i2b2\",\n",
    "        \"en_core_web_lg\"\n",
    "    \"\"\"\n",
    "  registry = RecognizerRegistry()\n",
    "  registry.load_predefined_recognizers()\n",
    "  if model_path == \"en_core_web_lg\":\n",
    "    nlp_configuration = {\n",
    "        \"nlp_engine_name\": \"spacy\",\n",
    "        \"models\": [{\"lang_code\": \"en\", \"model_name\": \"en_core_web_lg\"}],\n",
    "    }\n",
    "  elif model_path == \"custom_P_E\":\n",
    "    # nlp = spacy.load(\"models/P&E-model3/model-best\")\n",
    "    # registry.add_recognizer(SpacyRecognizer(nlp))\n",
    "    nlp_configuration = {\n",
    "        \"nlp_engine_name\": \"spacy\",\n",
    "        \"models\": [{\"lang_code\": \"en\", \"model_name\": \"models/P&E-model3/model-best\"}],\n",
    "    }\n",
    "  else:\n",
    "    # Using a small spaCy model + a HF NER model\n",
    "    transformers_recognizer = TransformersRecognizer(model_path=model_path)\n",
    "    if model_path == \"obi/deid_roberta_i2b2\":\n",
    "      transformers_recognizer.load_transformer(**BERT_DEID_CONFIGURATION)\n",
    "    else:\n",
    "      transformers_recognizer.load_transformer(**BERT_PII_CONFIGURATION)\n",
    "    # Use small spaCy model, no need for both spacy and HF models\n",
    "    # The transformers model is used here as a recognizer, not as an NlpEngine\n",
    "    nlp_configuration = {\n",
    "      \"nlp_engine_name\": \"spacy\",\n",
    "      \"models\": [{\"lang_code\": \"en\", \"model_name\": \"en_core_web_sm\"}],\n",
    "    }\n",
    "    registry.add_recognizer(transformers_recognizer)\n",
    "\n",
    "  nlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()\n",
    "\n",
    "  analyzer = AnalyzerEngine(nlp_engine=nlp_engine, registry=registry)\n",
    "  return analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(analyzer, **kwargs):\n",
    "    \"\"\"Analyze input using Analyzer engine and input arguments (kwargs).\"\"\"\n",
    "    if \"entities\" not in kwargs or \"All\" in kwargs[\"entities\"]:\n",
    "        kwargs[\"entities\"] = None\n",
    "    return analyzer.analyze(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize(text: str, analyze_results: List[RecognizerResult]):\n",
    "    \"\"\"Anonymize identified input using Presidio Anonymizer.\n",
    "    :param text: Full text\n",
    "    :param analyze_results: list of results from presidio analyzer engine\n",
    "    \"\"\"\n",
    "    operator_config = {\"lambda\": lambda x: x}\n",
    "    operator = \"custom\"\n",
    "    res = AnonymizerEngine().anonymize(\n",
    "        text,\n",
    "        analyze_results,\n",
    "        operators={\"DEFAULT\": OperatorConfig(operator, operator_config)},\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIAL CONFIG FOR THE ANALYZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = analyzer_engine(\"obi/deid_roberta_i2b2\") # \"en_core_web_lg\" or \"obi/deid_roberta_i2b2\" or \"custom_P_E\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.40\n",
    "entities = [\"PERSON\", \"LOCATION\", \"PHONE_NUMBER\", \"EMAIL_ADDRESS\",\"CREDIT_CARD\", \"US_SSN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_obj(an_r, text):\n",
    "    \"\"\"Show results of analyze() in a dataframe.\"\"\"\n",
    "    ents = []\n",
    "    for r in an_r:\n",
    "      info = r.to_dict()\n",
    "      ent ={ \"start\": info[\"start\"], \n",
    "              \"end\": info['end'], \n",
    "              \"confidence\": info['score'], \n",
    "              \"entity\": info['entity_type'], \n",
    "              \"text\": text[info[\"start\"]:info[\"end\"]]} \n",
    "      ents.append(ent)\n",
    "    return ents\n",
    "\n",
    "\n",
    "def model_results(csv_path, json_path, entities, threshold, analyzer,columns, check_overlaps=False):\n",
    "  results = []\n",
    "  df = pd.read_csv(csv_path, encoding=\"ISO-8859-1\",header=0, names=columns)\n",
    "  # file = open(csv_path, 'r', encoding=\"ISO-8859-1\")\n",
    "  # reader = csv.reader(file)\n",
    "  # rows = list(reader)\n",
    "  # for row in tqdm(rows, total=len(rows)):\n",
    "  for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    # id = row.PVID\n",
    "    # text = row.CONTENT\n",
    "    text = row[0]\n",
    "    analyze_results = analyze(\n",
    "      analyzer=analyzer,\n",
    "      text=text,\n",
    "      entities= entities,\n",
    "      language=\"en\",\n",
    "      score_threshold=threshold,\n",
    "    )\n",
    "    if check_overlaps: # return only entities without overlaps (resolved from presidio) and prediction.\n",
    "      text_anon = anonymize(text, analyze_results)\n",
    "      text_anon = sorted(text_anon.items, key=lambda x: x.start)\n",
    "      result = []\n",
    "      for i, res in enumerate(text_anon):\n",
    "          result.append({\"start\": res.start, \"end\": res.end, \"entity\": res.entity_type, \"text\": res.text})\n",
    "          \n",
    "    else: # return all entities with overlaps and prediction. \n",
    "      result = create_obj(analyze_results, text)\n",
    "    # results.append({\"PVID\": id, \"TEXT\": text, \"ENTITIES\": result})\n",
    "    results.append({\"TEXT\": text, \"ENTITIES\": result})\n",
    "  fp=open(json_path,'w', encoding=\"ISO-8859-1\") # output file\n",
    "  json.dump(results, fp)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST SIMPLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(text: str, analyze_results: List[RecognizerResult]):\n",
    "    \"\"\"\n",
    "    Highlights every identified entity on top of the text.\n",
    "    :param text: full text\n",
    "    :param analyze_results: list of analyzer results.\n",
    "    \"\"\"\n",
    "    ents = []\n",
    "\n",
    "    # Use the anonymizer to resolve overlaps\n",
    "    results = anonymize(text, analyze_results)\n",
    "    # sort by start index\n",
    "    results = sorted(results.items, key=lambda x: x.start)\n",
    "    for i, res in enumerate(results):\n",
    "        ents.append({\"start\": res.start, \"end\": res.end, \"label\": res.entity_type, \"text\": res.text})\n",
    "    return [{\"text\": text, \"ents\": ents}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(an_r, text, return_analyzer_results=False):\n",
    "    \"\"\"Show results of analyze() in a dataframe.\"\"\"\n",
    "    df = pd.DataFrame.from_records([r.to_dict() for r in an_r])\n",
    "    df[\"text\"] = [text[res.start: res.end] for res in an_r]\n",
    "    df_subset = df[[\"entity_type\", \"text\", \"start\", \"end\", \"score\"]].rename(\n",
    "        {\n",
    "            \"entity_type\": \"Entity type\",\n",
    "            \"text\": \"Text\",\n",
    "            \"start\": \"Start\",\n",
    "            \"end\": \"End\",\n",
    "            \"score\": \"Confidence\",\n",
    "        },\n",
    "        axis=1,\n",
    "    )\n",
    "    df_subset[\"Text\"] = [text[res.start: res.end] for res in an_r]\n",
    "    #  In analysis_explanation_df there are more columns than in df_subset with more information. \n",
    "    if return_analyzer_results:\n",
    "      analysis_explanation_df = pd.DataFrame.from_records(\n",
    "          [r.analysis_explanation.to_dict() for r in an_r]\n",
    "      )\n",
    "    # df_subset = pd.concat([df_subset, analysis_explanation_df], axis=1)\n",
    "    result = annotate(text, an_r)\n",
    "    return df_subset.reset_index(drop=True), result\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"My name is Gonzalo Zelinka, I'm from Argentina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_results = analyze(\n",
    "    analyzer=analyzer,\n",
    "    text=text,\n",
    "    entities= entities,\n",
    "    language=\"en\",\n",
    "    score_threshold=threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">My name is \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gonzalo Zelinka\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", I'm from \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Argentina\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOCATION</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity type</th>\n",
       "      <th>Text</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PERSON</td>\n",
       "      <td>Gonzalo</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PERSON</td>\n",
       "      <td>Zelinka</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOCATION</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PERSON</td>\n",
       "      <td>Gonzalo Zelinka</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Entity type             Text  Start  End  Confidence\n",
       "0      PERSON          Gonzalo     11   18        1.00\n",
       "1      PERSON          Zelinka     19   26        1.00\n",
       "2    LOCATION        Argentina     37   46        1.00\n",
       "3      PERSON  Gonzalo Zelinka     11   26        0.85"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame, sentence = show_results(analyze_results, text)\n",
    "# print(sentence)\n",
    "displacy.render(sentence, style=\"ent\", manual=True)\n",
    "display(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATE RESULTS FROM COMPLEX DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHANGE DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "#Change this\n",
    "os.chdir(\"\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(\"testing-data/product_reviews7_test_sentences.csv\", \"testing-data/product_reviews8.json\", entities, threshold, analyzer, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRACT THE DATA TRUTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span_indx(\n",
    "    labels: List[str],\n",
    "    words: List[str],\n",
    "    sentence: str\n",
    ") -> List[tuple]:\n",
    "    \"\"\"Gets span starts and ends for Spacy spancat component.\n",
    "        \n",
    "        Returns list of tuples where the first element of the \n",
    "        tuple is the span start, the second element of the tuple\n",
    "        is the span end and the third element of the tuple is\n",
    "        the span category. \n",
    "    \"\"\"\n",
    "    #gets list of indices corresponding to labelled words \n",
    "    label_indx = []\n",
    "    temp_list = []\n",
    "\n",
    "    for i, l in enumerate(labels):\n",
    "        if l != 'O':\n",
    "            temp_list.append(i)\n",
    "        else:\n",
    "            label_indx.append(temp_list)\n",
    "            temp_list = []    \n",
    "        if i == len(labels) - 1:\n",
    "            label_indx.append(temp_list)\n",
    "\n",
    "    clean_label_indx = [x for x in label_indx if len(x) > 0]\n",
    "\n",
    "    spans = []\n",
    "    for indx in clean_label_indx:\n",
    "        if len(indx) == 1:\n",
    "            span = words[indx[0]]\n",
    "            label = labels[indx[0]].upper()\n",
    "        else:\n",
    "            span = ' '.join([words[i] for i in indx])  \n",
    "            label = [labels[i].upper() for i in indx][0]\n",
    "        #remove punctuation and strip whitespace for spans\n",
    "        span_clean = span.strip()\n",
    "        for m in re.finditer(re.escape(span_clean), sentence):\n",
    "            spans.append({\"start\":m.start(), \"end\":m.end(), \"entity\": label, \"text\": m.group()})\n",
    "    \n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_csv_annotated_to_json(input_path):\n",
    "    DATA = []\n",
    "    data = (pd.read_csv(input_path, encoding='ISO-8859-1')\n",
    "          .fillna(method='ffill'))\n",
    "    for sent, sent_info in data.groupby('Review #'):\n",
    "      words = list(sent_info[\"Word\"])\n",
    "      #convert words to sentence and get rid of spaces between punctuation characters\n",
    "      sentence = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', \" \".join(words))\n",
    "      #get labels\n",
    "      labels = list(sent_info['Tag'])\n",
    "      #identify token span start, span ends and span category\n",
    "      span_ents = get_span_indx(labels, words, sentence)\n",
    "      DATA.append({\"TEXT\": sentence, \"ENTITIES\": span_ents})\n",
    "    return DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TEXT': 'Hi my name is Sofia thompson. I hate the Xiaomi , the design is awful. I expected more. My social sn is 068289873 and my credit number is 4881 8730 3709 2414', 'ENTITIES': [{'start': 14, 'end': 28, 'entity': 'PERSON', 'text': 'Sofia thompson'}, {'start': 104, 'end': 113, 'entity': 'US_SSN', 'text': '068289873'}, {'start': 138, 'end': 157, 'entity': 'CREDIT_CARD', 'text': '4881 8730 3709 2414'}]}\n"
     ]
    }
   ],
   "source": [
    "data_csv = transform_csv_annotated_to_json(\"testing-data/product_reviews9.csv\")\n",
    "with open('testing-data/true_data.json', 'w') as fp:\n",
    "    json.dump(data_csv, fp)\n",
    "print(data_csv[1999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract only sentences to send to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences(input_file, output_file):\n",
    "  data = (pd.read_csv(input_file, encoding='ISO-8859-1')\n",
    "    .fillna(method='ffill'))\n",
    "  with open(output_file, 'w', encoding='ISO-8859-1') as fo:\n",
    "    writer = csv.writer(fo)\n",
    "    writer.writerow(['SENTENCES']) \n",
    "    for sent, sent_info in data.groupby('Review #'):\n",
    "      words = list(sent_info[\"Word\"])\n",
    "      sentence = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', \" \".join(words))\n",
    "      writer.writerow([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_sentences(\"testing-data/product_reviews9.csv\", \"testing-data/sentences_evaluate.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN THE MODEL WITH THE EXTRACTED SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:01<00:00, 16.47it/s]\n"
     ]
    }
   ],
   "source": [
    "model_results(csv_path=\"testing-data/sentences_evaluate.csv\", json_path=\"testing-data/output_custom_P_E.json\", \n",
    "entities=entities, threshold=threshold, analyzer=analyzer, columns=[\"SENTENCES\"], check_overlaps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_array_evaluate_per_words(array):\n",
    "  \"\"\"Generate array for evaluation.\"\"\"\n",
    "  array_evaluate = []\n",
    "  text = array['TEXT']\n",
    "  for word in text.split(' '):\n",
    "    is_in = False\n",
    "    for entity in array[\"ENTITIES\"]:\n",
    "      if word in entity[\"text\"] and entity[\"entity\"] != \"LOCATION\":\n",
    "        is_in = True\n",
    "        break\n",
    "    if not is_in:\n",
    "      array_evaluate.append(\"O\")\n",
    "  return array_evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall_for_entities(ground_truth, predictions, output_file):\n",
    "    \"\"\"Calculate precision and recall.\"\"\"\n",
    "    gt_eval_array = []\n",
    "    pr_eval_array = []\n",
    "    for gt in ground_truth:\n",
    "        a_eval = generate_array_evaluate_per_words(gt)\n",
    "        gt_eval_array.append(a_eval)\n",
    "    for pr in predictions:\n",
    "        a_eval = generate_array_evaluate_per_words(pr)\n",
    "        pr_eval_array.append(a_eval)\n",
    "    # for i in range(2):\n",
    "    #     print(ground_truth[i])\n",
    "    #     print(gt_eval_array[i])\n",
    "    #     print(pr_eval_array[i])\n",
    "    # print(\"General Precision: \", accuracy_score(gt_eval_array, pr_eval_array))\n",
    "    # print(\"General Recall: \", recall_score(gt_eval_array, pr_eval_array))\n",
    "    # print(\"General F1: \", f1_score(gt_eval_array, pr_eval_array))\n",
    "    report = classification_report(gt_eval_array, pr_eval_array)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='ISO-8859-1') as f:\n",
    "        f.write(\"General Precision: \" + str(accuracy_score(gt_eval_array, pr_eval_array)) + \"\\n\")\n",
    "        f.write(\"General Recall: \" + str(recall_score(gt_eval_array, pr_eval_array)) + \"\\n\")\n",
    "        f.write(\"General F1: \" + str(f1_score(gt_eval_array, pr_eval_array)) + \"\\n\")\n",
    "        f.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"testing-data/output_roberta.json\", \"r\") as f:\n",
    "  json_data = f.read()\n",
    "prediction_data = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted entities from predictions_all\n",
    "entities_to_remove = ['ORGANIZATION', 'AGE', 'DATE_TIME', 'O']\n",
    "for i in range(len(prediction_data)):\n",
    "    entities = prediction_data[i]['ENTITIES']\n",
    "    for j in range(len(entities)-1, -1, -1):\n",
    "        if entities[j]['entity'] in entities_to_remove:\n",
    "            del entities[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gonzalo.zelinka/Desktop/PII_POC/.venv/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore', '.* seems not to be NE tag\\.')\n",
    "calculate_precision_recall_for_entities(data_csv, prediction_data, \"eval/REPORT_custom_P_E.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall_for_sentence(ground_truth_all, predictions_all, output_file):\n",
    "    \"\"\"Extract entities from ground truth and predictions.\"\"\"\n",
    "    gt_eval_array = []\n",
    "    pr_eval_array = []\n",
    "\n",
    "    for i in range(len(ground_truth_all)):\n",
    "        test = ground_truth_all[i]\n",
    "        test1 = predictions_all[i]\n",
    "        entities_gt = sorted(set(item['entity'] for item in test['ENTITIES']))\n",
    "        entities_pr = sorted(set(item['entity'] for item in test1['ENTITIES']))\n",
    "        \n",
    "        for entity in entities_gt:\n",
    "            if entity not in entities_pr:\n",
    "                entities_pr.insert(entities_gt.index(entity), 'O')\n",
    "                print(f\"Warning: entity {entity} not found in sample {i}\")\n",
    "\n",
    "        for entity in entities_pr:\n",
    "            if entity not in entities_gt:\n",
    "                entities_pr.insert(entities_pr.index(entity), 'O')\n",
    "                print(f\"Warning: entity {entity} not found in sample {i}\")\n",
    "        \n",
    "        print(f\"Ground truth: {entities_gt}\")\n",
    "        print(f\"Predictions: {entities_pr}\")\n",
    "\n",
    "        if len(entities_gt) != len(entities_pr):\n",
    "            print(f\"Warning: inconsistent number of entities in sample {i}\")\n",
    "            print(f\"Ground truth: {entities_gt}\")\n",
    "            print(f\"Predictions: {entities_pr}\")\n",
    "            continue\n",
    "        \n",
    "        gt_eval_array.append(entities_gt)\n",
    "        pr_eval_array.append(entities_pr)\n",
    "    \n",
    "    report = classification_report(gt_eval_array, pr_eval_array)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='ISO-8859-1') as f:\n",
    "        f.write(\"General Precision: \" + str(accuracy_score(gt_eval_array, pr_eval_array)) + \"\\n\")\n",
    "        f.write(\"General Recall: \" + str(recall_score(gt_eval_array, pr_eval_array)) + \"\\n\")\n",
    "        f.write(\"General F1: \" + str(f1_score(gt_eval_array, pr_eval_array)) + \"\\n\")\n",
    "        f.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_entities(arrays):\n",
    "    unique_entities = set()\n",
    "    for array in arrays:\n",
    "        unique_entities |= set(array)\n",
    "    return sorted(list(unique_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_precision_recall_for_sentence(data_csv[0:2], prediction_data[0:2], \"eval/REPORT_SENTENCE.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 21, 'end': 33, 'entity': 'PERSON', 'text': 'Zoey Edwards'}, {'start': 129, 'end': 151, 'entity': 'EMAIL_ADDRESS', 'text': 'edwards-zoey@gmail.com'}, {'start': 190, 'end': 201, 'entity': 'LOCATION', 'text': '900 F St NW'}, {'start': 213, 'end': 222, 'entity': 'US_SSN', 'text': '367245504'}, {'start': 252, 'end': 271, 'entity': 'CREDIT_CARD', 'text': '2259-8740-7030-1462'}]\n",
      "[{'start': 21, 'end': 33, 'entity': 'PERSON', 'text': 'Zoey Edwards'}, {'start': 129, 'end': 151, 'entity': 'EMAIL_ADDRESS', 'text': 'edwards-zoey@gmail.com'}, {'start': 190, 'end': 195, 'entity': 'LOCATION', 'text': '900 F'}, {'start': 196, 'end': 201, 'entity': 'LOCATION', 'text': 'St NW'}, {'start': 213, 'end': 222, 'entity': 'US_SSN', 'text': '367245504'}, {'start': 252, 'end': 255, 'entity': 'PHONE_NUMBER', 'text': '225'}, {'start': 255, 'end': 271, 'entity': 'PHONE_NUMBER', 'text': '9-8740-7030-1462'}]\n"
     ]
    }
   ],
   "source": [
    "print(data_csv[7][\"ENTITIES\"])\n",
    "print(prediction_data[7][\"ENTITIES\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a9f895cc7e3ca0d623982e8f7234235464dc9c0b943e7d04631c8d05e4aca2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
